<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | Knowledge Capture And Discovery</title><link>https://knowledgecaptureanddiscovery.github.io/project/</link><atom:link href="https://knowledgecaptureanddiscovery.github.io/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 09 May 2022 16:21:55 -0700</lastBuildDate><image><url>https://knowledgecaptureanddiscovery.github.io/media/icon_hu93f87f9778d3397b7e8789483b06b096_16900_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://knowledgecaptureanddiscovery.github.io/project/</link></image><item><title>MINT</title><link>https://knowledgecaptureanddiscovery.github.io/project/mint/</link><pubDate>Mon, 09 May 2022 16:09:50 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/mint/</guid><description>&lt;h2 id="link">Link&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://mint.isi.edu" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dev.mint.isi.edu" target="_blank" rel="noopener">Dev Website&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/mintproject" target="_blank" rel="noopener">GitHub organization&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mintproject.readthedocs.io/en/latest/" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Linked Earth</title><link>https://knowledgecaptureanddiscovery.github.io/project/linkedearth/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/linkedearth/</guid><description/></item><item><title>Wings</title><link>https://knowledgecaptureanddiscovery.github.io/project/wings/</link><pubDate>Mon, 09 May 2022 16:21:55 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/wings/</guid><description>&lt;p>WINGS is a semantic workflow system that assists scientists with the design of computational experiments. A unique feature of WINGS is that its workflow representations incorporate semantic constraints about datasets and workflow components, and are used to create and validate workflows and to generate metadata for new data products. WINGS submits workflows to execution frameworks such as Pegasus and OODT to run workflows at large scale in distributed resources.&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="#">Website&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="#">User Guide&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="#">Developer Guide&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/wings" target="_blank" rel="noopener">Repo&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://datascience4all.org/wings-portal-new/" target="_blank" rel="noopener">Data4Science Instances&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.wings-workflows.org/wings-omics-portal/" target="_blank" rel="noopener">OMICS&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://enigma-disk.wings.isi.edu/wings-portal/login" target="_blank" rel="noopener">Enigma&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>DISK</title><link>https://knowledgecaptureanddiscovery.github.io/project/disk/</link><pubDate>Mon, 09 May 2022 16:09:29 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/disk/</guid><description>&lt;p>DISK is a novel framework to test and revise hypotheses based on automatic analysis of scientific data repositories that grow over time. Given an input hypothesis, DISK is able to search for appropriate data to test it and revise it accordingly, and does this continuously as new data be-comes available. DISK is also capable of triggering new kinds of analyses when new kinds of data become available.
The provenance of the revised hypotheses is recorded, with all the details of the analyses.
Ongoing research includes extending DISK to generate interactive explanations for scientists based on provenance records, developing a general approach to the design of meta-workflows, handling more complex hypotheses, and exploring the use of this approach in other areas of science.&lt;/p>
&lt;p>Links:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://www.disk-project.org/" target="_blank" rel="noopener">Website&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://disk.readthedocs.io/en/stable/" target="_blank" rel="noopener">User Guide&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://neuro.disk.isi.edu/" target="_blank" rel="noopener">NeuroDISK portal&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="http://climate.disk.isi.edu/" target="_blank" rel="noopener">ClimateDISK portal&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Repositories&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/DISK-WEB" target="_blank" rel="noopener">DISK general&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/DISK-UI" target="_blank" rel="noopener">DISK UI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>NeuroDISK</title><link>https://knowledgecaptureanddiscovery.github.io/project/neuro-disk/</link><pubDate>Mon, 09 May 2022 16:09:29 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/neuro-disk/</guid><description>&lt;p>There is abundant brain image and genetic data for researchers to understand brain structure, functions and disease. It is challenging to carry out comprehensive analyses that integrate available data. Though data generation is continuous, analyses are seldom repeated and their results updated.&lt;/p>
&lt;p>The Neuro-DISK project automates the analysis of neuroscience data through artificial intelligence (AI).
NeuroDISK is an AI-driven discovery engine that will continually processes neuroscience data.
We use ontologies of hypotheses to represent science driving questions, semantic representations to reason about the data available, machine learning to improve accuracy, and intelligent workflows to customize the analysis to the data.
Given a science question, NeuroDISK autonomously determines what data is needed, triggers the execution of relevant families of workflows, customize them to the data at hand, and alert users of interesting findings.&lt;/p>
&lt;p>We are developing NeuroDISK in collaboration with researchers from the ENIGMA consortium who study different neuroscience questions.&lt;/p>
&lt;p>Links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://knowledgecaptureanddiscovery.github.io/NeuroDISK/" target="_blank" rel="noopener">NeuroDISK landing page&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://neuro.disk.isi.edu/" target="_blank" rel="noopener">NeuroDISK page&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Repositories&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/DISK-WEB" target="_blank" rel="noopener">DISK general&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/DISK-UI" target="_blank" rel="noopener">DISK UI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Climate DISK</title><link>https://knowledgecaptureanddiscovery.github.io/project/climate-disk/</link><pubDate>Mon, 09 May 2022 16:09:29 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/climate-disk/</guid><description>&lt;p>Climate DISK uses the DISK framework to automate climate analysis using observational paleoclimate data stored on the LinkedEarth platform (in the LiPD format).
These datasets consist of paleoclimate measurements (such as tree ring width, the isotopic composition of ice, bulk composition of marine and lake sediments) as a proxy for past environmental variables such as temperature and precipitation.&lt;/p>
&lt;p>Links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://climate.disk.isi.edu/" target="_blank" rel="noopener">Climate DISK page&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://wiki.linked.earth/Main_Page" target="_blank" rel="noopener">LinkedEarth platform&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Repositories&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/DISK-WEB" target="_blank" rel="noopener">DISK general&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/DISK-UI" target="_blank" rel="noopener">DISK UI&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>autoTS</title><link>https://knowledgecaptureanddiscovery.github.io/project/autots/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/autots/</guid><description>&lt;p>autoTS is an automated system for time series analysis that uses semnatic workflows to represent sophisticated methods and their constraints. AutoTs extends the &lt;a href="https://www.wings-workflows.org" target="_blank" rel="noopener">WINGS workflow system&lt;/a> with new capbilities to cutomize general methods to specific datasets based on key characteristics of the data.&lt;/p>
&lt;p>The methods are encapsulated in the &lt;a href="http://linkedearth.github.io/Pyleoclim_util/" target="_blank" rel="noopener">Pyleoclim package&lt;/a>&lt;/p>
&lt;p>This repository contains the following:&lt;/p>
&lt;ul>
&lt;li>Notebooks the describe a certain methodology and workflow strategies&lt;/li>
&lt;li>Sample data with know characteristics (e.g. periodicity, noise, amount of missing data) to test the methods and workflow strategies.&lt;/li>
&lt;li>Code to automatically profile data (e.g. trend)&lt;/li>
&lt;/ul>
&lt;h2 id="further-information">Further information&lt;/h2>
&lt;p>Fore more information about the project, visit our website.&lt;/p>
&lt;h2 id="contact">Contact&lt;/h2>
&lt;p>Please report issues to &lt;a href="mailto:khider@usc.edu">khider@usc.edu&lt;/a>&lt;/p>
&lt;h2 id="license">License&lt;/h2>
&lt;p>The material on this repository is licensed under the Apache 2.0 License.&lt;/p>
&lt;h2 id="disclaimer">Disclaimer&lt;/h2>
&lt;p>This research is funded by JP Morgan Chase &amp;amp; Co. Any views or opinions expressed herein are solely those of the authors listed, and may differ from the views and opinions expressed by JP Morgan Chase &amp;amp; Co. or its affilitates. This material is not a product of the Research Department of J.P. Morgan Securities LLC. This material should not be construed as an individual recommendation of for any particular client and is not intended as a recommendation of particular securities, financial instruments or strategies for a particular client. This material does not constitute a solicitation or offer in any jurisdiction.&lt;/p></description></item><item><title>The Geoscience Paper of the Future Initiative</title><link>https://knowledgecaptureanddiscovery.github.io/project/gpf/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/gpf/</guid><description>&lt;p>Overview&lt;/p>
&lt;p>In the near future, scientists will routinely use new tools to develop research papers that will document all the associated digital objects (data, software, workflows, etc.). This will make science more open, promote fair credit of scientific contributions, and facilitate reproducibility.&lt;/p>
&lt;p>The Geoscience Papers of the Future (GPF) is an initiative to encourage geoscientists to publish papers together with the associated digital products of their research. This means that a paper would include: 1) Documentation of datasets, including descriptions, unique identifiers, and availability in public repositories; 2) Documentation of software, including pre-processing of data and visualization steps, described with metadata and with unique identifiers and pointers to public code repositories; 3) Documentation of the provenance and workflow for each figure or result.&lt;/p>
&lt;p>The Geoscience Papers of the Future Initiative has two major components:&lt;/p>
&lt;pre>&lt;code>A Special Section of the AGU Earth and Space Science journal that will highlight GPFs. We have partnered with the largest scientific society in geosciences to create a special issue of their new cross-disciplinary journal to encourage submissions of GPFs that will help move the geosciences community to publish all digital objects resulting from their research.
A training program that offers training sessions for geoscientists to learn best practices in software and data sharing, provenance documentation, and scholarly publication. These training sessions will be offered in different modalities throughout 2015 (e.g. AGU Fall Meeting, GSA, ESIP, etc.). Training materials will be freely available on line. Training sessions will be offered upon request at other institutions and community events.
&lt;/code>&lt;/pre>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.scientificpaperofthefuture.org/gpf/" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Asset</title><link>https://knowledgecaptureanddiscovery.github.io/project/asset/</link><pubDate>Mon, 09 May 2022 16:21:53 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/asset/</guid><description>&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.earthcube.org/group/accelerating-scientific-workflows-using-earthcube-technologies-asset" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Data Narratives</title><link>https://knowledgecaptureanddiscovery.github.io/project/dana/</link><pubDate>Mon, 09 May 2022 16:21:53 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/dana/</guid><description>&lt;p>DAta NArratives (DANA)&lt;/p>
&lt;p>Data Narratives are containers of information about computationally generated data.&lt;/p>
&lt;p>Check out some Data Narratives examples or browse the code on Github.&lt;/p>
&lt;p>Data narratives have three major components:&lt;/p>
&lt;p>A record of events, that describe a new result through a workflow and/or provenance of all the computations executed;
Persistent entries for key entities involved through DOIs for data, software versions, and workflow;
a narrative account (or several), that is an automatically generated human-consumable rendering of the record and entities and may include visualizations or summaries.&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://knowledgecaptureanddiscovery.github.io/DataNarratives/" target="_blank" rel="noopener">website&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Fragflow</title><link>https://knowledgecaptureanddiscovery.github.io/project/fragflow/</link><pubDate>Mon, 09 May 2022 16:21:53 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/fragflow/</guid><description>&lt;h1 id="fragflow">FragFlow&lt;/h1>
&lt;p>Project designed for finding internal macro and composite workflow motifs in scientific workflow, defined according to&lt;/p>
&lt;p>&lt;a href="http://purl.org/net/wf-motifs#InternalMacro" target="_blank" rel="noopener">http://purl.org/net/wf-motifs#InternalMacro&lt;/a> and &lt;a href="http://purl.org/net/wf-motifs#CompositeWorkflow" target="_blank" rel="noopener">http://purl.org/net/wf-motifs#CompositeWorkflow&lt;/a>.&lt;/p>
&lt;p>The project finds a set of workflow fragments from workflow specifications and/or workflow executions and links
the results to the corpus. The results are linked according to the Workflow Fragment Description Ontology: &lt;a href="http://purl.org/net/wf-fd" target="_blank" rel="noopener">http://purl.org/net/wf-fd&lt;/a>&lt;/p>
&lt;p>In order to achieve the results, this project defines diverse operations for graph manipulation and formatting. In particular:&lt;/p>
&lt;ul>
&lt;li>Generic readers and writers that can read and write different workflow specifications and traces (currently supported: OPMW, OPM)&lt;/li>
&lt;li>Inference and abstraction of a workfow collection or individual workflows.&lt;/li>
&lt;li>Remote querying and adaptation to process RDF workflows exposed as Linked Data.&lt;/li>
&lt;li>Formatting output to be read by the SUBDUE and PAFI tools.&lt;/li>
&lt;li>Capability of saving the results as RDF.&lt;/li>
&lt;li>Computation of statistics on the results obtained, and binding the fragments proposed by the tools to the results.&lt;/li>
&lt;/ul>
&lt;p>The project is configured as a Netbeans project right now. All the libraries and dependencies are jar files contained in the /lib folder.&lt;/p>
&lt;p>Current ongoing work:&lt;/p>
&lt;ul>
&lt;li>Adapt the framework to different types of graph mining algorithms. Currently supported: SUBDUE, PAFI, Parsemis (gSpan, Gaston(ongoing))&lt;/li>
&lt;li>Adapt the framework to read from different types of workflows. Currently supported: OPMW, LONI Pipeline&lt;/li>
&lt;/ul></description></item><item><title>Ontosoft</title><link>https://knowledgecaptureanddiscovery.github.io/project/ontosoft/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/ontosoft/</guid><description>&lt;p>The OntoSoft project is part of the NSF EarthCube Initiative. The NSF EarthCube Initiative aims to enable scientists to solve challenging problems that span diverse geoscience domains. This requires not only data sharing, it requires new forms of knowledge sharing. The focus of OntoSoft is to promote knowledge sharing about the software developed for geosciences.&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://ontosoft.isi.edu/" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>OPMW-PROV: The Open Provenance Model for Workflows</title><link>https://knowledgecaptureanddiscovery.github.io/project/opmw/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/opmw/</guid><description>&lt;p>OPMW is an ontology for describing workflows based on the Open Provenance Model. It has been designed as a profile for OPM, extending and reusing OPM&amp;rsquo;s core ontologies OPMV (OPM-Vocabulary) and OPMO (OPM-Ontology). Since the publication of the PROV-O standard, the ontology also extends the W3C recommendation.&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.opmw.org/" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Organic Data Curation</title><link>https://knowledgecaptureanddiscovery.github.io/project/odc/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/odc/</guid><description>&lt;p>We are investigating a novel approach to data publishing that is organic in its organization, requires minimal effort from the contributor, has parsimonious design, and is accessible to all scientists as well as other potential contributors. We offer a minimal pre-defined structure, and allow contributors to describe their data by easily defining their own metadata properties to suit their particular datasets, and to reuse common available vocabularies when it is convenient. The normalization of metadata will be organic, as other scientists aggregate datasets in the repository and find the need to aggregate them.&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.organicdatacuration.org/" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Organic Data Science Framework</title><link>https://knowledgecaptureanddiscovery.github.io/project/ods/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/ods/</guid><description>&lt;p>Over the last hundred years, science has become an increasingly collaborative endeavor. Scientific collaborations, sometimes referred to as â€œcollaboratoriesâ€ and â€œvirtual organizationsâ€, range from those that work closely together and others that are more loosely coordinated. Some scientific collaborations revolve around sharing instruments (e.g., the Large Hadron Collider), others focus on a shared database (e.g., the Sloan Sky Digital Survey), others form around a shared software base (e.g., SciPy), and others around a shared scientific question (e.g., the Human Genome Project).&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.organicdatascience.org/" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/KnowledgeCaptureAndDiscovery/ODS_wiki_generic" target="_blank" rel="noopener">Semantic Wiki&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>P4ml</title><link>https://knowledgecaptureanddiscovery.github.io/project/p4ml/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/p4ml/</guid><description>&lt;p>First release of the P4ML system (ISI TA2). The system supports:&lt;/p>
&lt;pre>&lt;code>Generation of pipelines by using the D3M primitive catalog
Automated dataset featurization and profiling to create appropriate pipelines
Automated hyperparameter tuning of pipelines
Ensembling of best results.
Multiprocessing
Generation of best solution within a time budget.
&lt;/code>&lt;/pre>
&lt;p>Source code repository: &lt;a href="https://github.com/usc-isi-i2/dsbox-ta2" target="_blank" rel="noopener">https://github.com/usc-isi-i2/dsbox-ta2&lt;/a>&lt;/p></description></item><item><title>The Scientific Paper of the Future Initiative</title><link>https://knowledgecaptureanddiscovery.github.io/project/spf/</link><pubDate>Mon, 09 May 2022 16:21:54 -0700</pubDate><guid>https://knowledgecaptureanddiscovery.github.io/project/spf/</guid><description>&lt;h2 id="links">Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.scientificpaperofthefuture.org/gpf/" target="_blank" rel="noopener">Website&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>